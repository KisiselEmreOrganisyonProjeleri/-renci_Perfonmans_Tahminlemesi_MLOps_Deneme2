{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/-renci_Perfonmans_Tahminlemesi_MLOps_Deneme2/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/-renci_Perfonmans_Tahminlemesi_MLOps_Deneme2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformConfig:\n",
    "    root_dir: Path  # Türü belirtmek için ':' kullanın\n",
    "    preprocessor_file: Path  # Türü belirtmek için ':' kullanın\n",
    "    data_path: Path  # Türü belirtmek için ':' kullanın"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ÖğrenciTahminleme.constants import * # constanst icerisinde degiskenleri import ettik\n",
    "from src.ÖğrenciTahminleme.utils.common import read_yaml, create_directories # common.py icerisinde read_yaml ve create_directories methodlarini import ettik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_data_transformation_config(self) -> DataTransformConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "        data_transformation_config = DataTransformConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            preprocessor_file = Path(config.preprocessor_file)\n",
    "        )\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from src.ÖğrenciTahminleme import logger\n",
    "from src.ÖğrenciTahminleme.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ÖğrenciTahminleme.utils.common import save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransfrom:\n",
    "    def __init__(self,config: DataTransformConfig): \n",
    "        self.config = config \n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        '''\n",
    "        This function si responsible for data trnasformation\n",
    "        \n",
    "        '''\n",
    "        try:\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "            categorical_columns = [\n",
    "                \"gender\",\n",
    "                \"race_ethnicity\",\n",
    "                \"parental_level_of_education\",\n",
    "                \"lunch\",\n",
    "                \"test_preparation_course\",\n",
    "            ]\n",
    "\n",
    "            num_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\",StandardScaler())\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline=Pipeline(\n",
    "\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"one_hot_encoder\",OneHotEncoder()),\n",
    "                (\"scaler\",StandardScaler(with_mean=False))\n",
    "                ]\n",
    "\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Categorical columns: {categorical_columns}\")\n",
    "            logger.info(f\"Numerical columns: {numerical_columns}\")\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "            )\n",
    "\n",
    "            return preprocessor\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def initiate_data_transformation(self):\n",
    "\n",
    "        try:\n",
    "            data = pd.read_csv(self.config.data_path)\n",
    "            train_df,test_df = train_test_split(data)\n",
    "\n",
    "            logger.info(\"Read train and test data completed\")\n",
    "\n",
    "            logger.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            preprocessing_obj=self.get_data_transformer_object()\n",
    "\n",
    "            target_column_name=\"math_score\"\n",
    "            numerical_columns = [\"writing_score\", \"reading_score\"]\n",
    "\n",
    "            input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df=test_df[target_column_name]\n",
    "\n",
    "            logger.info(\n",
    "                f\"Applying preprocessing object on training dataframe and testing dataframe.\"\n",
    "            )\n",
    "\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "            ]\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            logger.info(f\"Saved preprocessing object.\")\n",
    "\n",
    "            save_object(\n",
    "\n",
    "                file_path=self.config.preprocessor_file,\n",
    "                obj=preprocessing_obj\n",
    "\n",
    "            )\n",
    "\n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr,\n",
    "                self.config.preprocessor_file,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 22:26:11,511: INFO: 323158990: Read train and test data completed]\n",
      "[2025-01-17 22:26:11,511: INFO: 323158990: Obtaining preprocessing object]\n",
      "[2025-01-17 22:26:11,513: INFO: 323158990: Categorical columns: ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']]\n",
      "[2025-01-17 22:26:11,514: INFO: 323158990: Numerical columns: ['writing_score', 'reading_score']]\n",
      "[2025-01-17 22:26:11,516: INFO: 323158990: Applying preprocessing object on training dataframe and testing dataframe.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 22:26:11,540: INFO: 323158990: Saved preprocessing object.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager() #benim değişkenlerimin değerlerini tutuyor.\n",
    "    data_transformation_config = config.get_data_transformation_config() # bu methodla config.yaml içindeki bütün değerleri çağırıyorum\n",
    "    data_transformation = DataTransfrom(config=data_transformation_config)\n",
    "    train_arr,test_arr,_ = data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    prep_data_path: Path\n",
    "    model_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ÖğrenciTahminleme.constants import * # constanst icerisinde degiskenleri import ettik\n",
    "from src.ÖğrenciTahminleme.utils.common import read_yaml, create_directories # common.py icerisinde read_yaml ve create_directories methodlarini import ettik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        create_directories([config.root_dir])\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            prep_data_path = config.prep_data_path,\n",
    "            model_file = Path(config.model_path)\n",
    "        )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score # Yüzdelik olarak modelin ne kadar doğru çalıştığını gösterir\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from src.ÖğrenciTahminleme import logger\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    " \n",
    "from src.ÖğrenciTahminleme.utils.common import get_size,save_object,evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from src.ÖğrenciTahminleme.utils.common import read_yaml  # Mevcut read_yaml fonksiyonunu kullanıyoruz\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig,params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = config\n",
    "        self.params = read_yaml(PARAMS_FILE_PATH)  # params path config'den okunur\n",
    "\n",
    "    def initiate_model_trainer(self, train_array, test_array):\n",
    "        try:\n",
    "            logger.info(\"Train ve test verisiyle model eğitimi başlatılıyor.\")\n",
    "            \n",
    "            X_train, y_train, X_test, y_test = (\n",
    "                train_array[:, :-1],\n",
    "                train_array[:, -1],\n",
    "                test_array[:, :-1],\n",
    "                test_array[:, -1],\n",
    "            )\n",
    "\n",
    "            models = {\n",
    "                \"Random Forest\": RandomForestRegressor(),\n",
    "                \"Decision Tree\": DecisionTreeRegressor(),\n",
    "                \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "                \"Linear Regression\": LinearRegression(),\n",
    "                \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "                \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "            }\n",
    "\n",
    "            # Parametreleri params.yaml dosyasından oku\n",
    "            params = self.params\n",
    "\n",
    "            model_report = {}\n",
    "            for model_name, model in models.items():\n",
    "                if model_name in params:\n",
    "                    param_grid = params[model_name]\n",
    "                    if param_grid:  # Eğer model için parametre tanımlandıysa\n",
    "                        logger.info(f\"{model_name} için RandomizedSearchCV başlatılıyor.\")\n",
    "                        search = RandomizedSearchCV(\n",
    "                            estimator=model,\n",
    "                            param_distributions=param_grid,\n",
    "                            scoring=\"r2\",\n",
    "                            n_iter=10,  # Rastgele 10 kombinasyonu değerlendir\n",
    "                            cv=3,  # 3-fold cross-validation\n",
    "                            random_state=42,\n",
    "                            n_jobs=-1\n",
    "                        )\n",
    "                        search.fit(X_train, y_train)\n",
    "                        best_model = search.best_estimator_\n",
    "                        model_report[model_name] = best_model.score(X_test, y_test)\n",
    "                    else:\n",
    "                        logger.info(f\"{model_name} için parametre yok, varsayılan model kullanılıyor.\")\n",
    "                        model.fit(X_train, y_train)\n",
    "                        model_report[model_name] = model.score(X_test, y_test)\n",
    "                else:\n",
    "                    logger.warning(f\"{model_name} için params.yaml'de parametre bulunamadı.\")\n",
    "\n",
    "            # En iyi modeli bul\n",
    "            best_model_name = max(model_report, key=model_report.get)\n",
    "            best_model_score = model_report[best_model_name]\n",
    "            best_model = models[best_model_name]\n",
    "\n",
    "            if best_model_score < 0.6:\n",
    "                raise Exception(\"Hiçbir model yeterli performansı sağlayamadı.\")\n",
    "\n",
    "            logger.info(f\"En iyi model: {best_model_name} (R2: {best_model_score})\")\n",
    "\n",
    "            # Modeli kaydet\n",
    "            save_object(\n",
    "                file_path=self.config.model_file / \"best_model.pkl\",\n",
    "                obj=best_model\n",
    "            )\n",
    "\n",
    "            predicted = best_model.predict(X_test)\n",
    "            r2_square = r2_score(y_test, predicted)\n",
    "            return best_model, r2_square\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model eğitimi sırasında hata oluştu: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 23:10:59,020: INFO: 3420584700: Train ve test verisiyle model eğitimi başlatılıyor.]\n",
      "[2025-01-17 23:10:59,020: INFO: 3420584700: Random Forest için RandomizedSearchCV başlatılıyor.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 23:11:02,569: INFO: 3420584700: Decision Tree için RandomizedSearchCV başlatılıyor.]\n",
      "[2025-01-17 23:11:02,743: INFO: 3420584700: Gradient Boosting için RandomizedSearchCV başlatılıyor.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 23:11:04,665: INFO: 3420584700: Linear Regression için parametre yok, varsayılan model kullanılıyor.]\n",
      "[2025-01-17 23:11:04,667: INFO: 3420584700: CatBoosting Regressor için RandomizedSearchCV başlatılıyor.]\n",
      "[2025-01-17 23:11:07,400: INFO: 3420584700: AdaBoost Regressor için RandomizedSearchCV başlatılıyor.]\n",
      "[2025-01-17 23:11:11,267: INFO: 3420584700: En iyi model: Linear Regression (R2: 0.88122153283977)]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager() #benim değişkenlerimin değerlerini tutuyor.\n",
    "    model_trainer_config = config.get_model_trainer_config() # bu methodla config.yaml içindeki bütün değerleri çağırıyorum\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.initiate_model_trainer(train_arr,test_arr)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
